<!DOCTYPE html>
<!--
test
Template Name: Wavefire
Author: <a href="https://www.os-templates.com/">OS Templates</a>
Author URI: https://www.os-templates.com/
Copyright: OS-Templates.com
Licence: Free to use under our free template licence terms
Licence URI: https://www.os-templates.com/template-terms
-->
<html lang="">
<!-- To declare your language - read more here: https://www.w3.org/International/questions/qa-html-language-declarations -->
<head>
<title>DAWN | Webinar | The Best of EDA Reserach in 2021 (April 11-12, 2022)</title>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
<link href="layout/styles/layout.css" rel="stylesheet" type="text/css" media="all">
<link rel="icon" href="images/DAWN.jpg">
</head>
<body id="top">

<!-- ################################################################################################ -->
<div class="wrapper row0">
  <header id="header" class="hoc clear"> 
	<!--logo-->
    <div id="logo" class="one_quarter first">
      <a href="index.html"><img src="images/DAWN.jpg"></a>
    </div>
	<!--drop down menu-->
    <div class="two_quarter">
    	<nav id="mainav">
      		<ul class="clear">
				
      <li  class="active"><a href="index.html">Home</a></li>
				
      <li><a class="drop" href="#">&nbsp Webinar</a> 
        <ul>
			<li><a href="https://duke-cei-lab.github.io/DAWN/" target="_blank">Previous Events</a></li>
        	<li><a href="BestEDAResearch2021.html">The Best of EDA Reserach in 2021<br>
				(April 11-12, 2022)</a></li>
        </ul>
      
    </ul>
    	</nav>
    </div>
	
<!--	<div id="searchform" >
      <div>
        <form action="#" method="post">
          <fieldset>
            <legend>Quick Search:</legend>
            <input type="text" placeholder="Enter search term&hellip;">
            <button type="submit"><i class="fas fa-search"></i></button>
          </fieldset>
        </form>
      </div>
    </div>-->
    <!-- ################################################################################################ -->
  </header>
</div>
<!-- Banner information -->
<div class="wrapper bgded overlay" style="background-image:url('images/11.png');">
    <div id="breadcrumb" class="hoc clear"> 
    	<h4 style="font-size:48px;">The Best of EDA Research in 2021</h4>
		<ul>
			
      <li><a style="font-size:18px" href="index.html">Home</a></li>
			
      <li><a style="font-size:18px" href="#">Webinar</a></li>
			
      <li><a style="font-size:18px" href="#">The Best of EDA Research in 2021 (April 11-12, 2022)</a></li>
		</ul>
    </div>
</div>
<!-- ################################################################################################ -->
<div class="row1">
  <main class="hoc container clear "> 
	<!-- Menu information -->
	<div class="sidebar one_quarter first">
		<h3>The Best of EDA Research in 2021 <br>(April 11-12, 2022)</h3>
		<nav class="sdb_holder">
			<ul>
				<!-- <li><a href="#overview">Overview</a></li> -->
				<li><b><font color="blue" style="font-size:20px" >April 11, 2022</font></b></li>
				<li><a href="#talk1">Talk 1: Hardware/Software Co-Exploration of Neural Architectures<br>(10AM-10:20AM, UTC-4)</a></li>
				<li><a href="#talk2">Talk 2: BOOM-Explorer: RISC-V BOOM Microarchitecture Design Space Exploration Framework<br>(10:20AM-10:40AM, UTC-4)</a></li>
				<li><a href="#talk3">Talk 3: APOLLO: An Automated Power Modeling Framework for Runtime Power Introspection in High-Volume Commercial Microprocessors<br>(10:40AM-11AM, UTC-4)</a></li>
				<li><a href="#talk4">Talk 4: Gemmini: Enabling Systematic Deep-Learning Architecture Evaluation via Full-Stack Integration<br>(11AM-11:20AM, UTC-4)</a></li>
				<br>
				<li><b><font color="blue" style="font-size:20px" >April 12, 2022</font></b></li>
				<li><a href="#talk5">Talk 5: DREAMPlace: Deep Learning Toolkit-Enabled GPU Acceleration for Modern VLSI Placement<br>(10AM-10:20AM, UTC-4)</a></li>
				<li><a href="#talk6">Talk 6: TreeNet: Deep Point Cloud Embedding for Routing Tree Construction<br>(10:20AM-10:40AM, UTC-4)</a></li>
				<li><a href="#talk7">Talk 7: Intermittent-Aware Neural Architecture Search<br>(10:40AM-11AM, UTC-4)</a></li>
				<li><a href="#talk8">Talk 8: A GPU-accelerated Deep Stereo-LiDAR Fusion for Real-time High-precision Dense Depth Sensing<br>(11AM-11:20AM, UTC-4)</a></li>
			</ul>
		</nav>
	</div>


	<div class="three_quarter wrapper">
		<div class="wrapper" id="overview">
			<!--Overview of this webinar-->
			<div>
				<h1>Overview</h1>
				<!--<h4><a href="TBD">Zoom Meeting Link</a></h4>-->
				<h4><font color="blue">The zoom link: </font>
					<a href="https://us06web.zoom.us/webinar/register/5716487609472/WN_HvF5i4ETR0uPGWf0YUt66Q" target="_blank">https://us06web.zoom.us/webinar/register/5716487609472/WN_HvF5i4ETR0uPGWf0YUt66Q.</a><br> 
					This link will bring you to the Webinar Registration page. After you fill up your name and email address, you can click the "register" button and the system will generate and show a link for you to join the webinar immediately. 
				</h4>
				<hr>
				<h4 style="text-align: justify;"> This webinar, called "The best of EDA research in 2021", invites the researchers to give talks about their papers that received best paper awards from EDA-related journals (e.g., IEEE TCAD) and conferences (including MICRO, DAC, ICCAD, DATE, ASP-DAC, and ESWEEK) in Year 2021.
				<br>This is a two-day webinar at <font color="blue">10:00AM-11:20AM EDT/UTC-4 (i.e., 10:00PM-11:20PM UTC+8), April 11-12 (Mon-Tue), 2022</font>. Each day includes four talks, where Talks 1-4 are on April 11 and Talks 5-8 are on April 12. Each talk is 20 minutes long and is divided into a 15-min presentation session and a 5-min Q&amp;A session. </i></h4>
				<hr>
				<h2>Moderators</h2>
				<h4><a href="https://www.cse.cuhk.edu.hk/people/faculty/tsung-yi-ho/" target="_blank">Tsung-Yi Ho</a>, The Chinese University of Hong Kong, Hong Kong</h4>
				<h4><a href="https://www.iis.sinica.edu.tw/~johnson/" target="_blank">Yuan-Hao Chang</a>, Academia Sinica, Taiwan</h4>
		
				<hr>
				<h2>April 11, 2022 (EDT/UTC-4)</h2>
				<table style="border: none;"><h5>
					<tr>
						<td  style="border: none;background-color: #fcf3ec;"><h5><nobr>10:00AM-10:20AM</nobr></h5></td>
						<td  style="border: none;background-color: #fcf3ec;"><h5><a href="#talk1">Talk 1: Hardware/Software Co-Exploration of Neural Architectures</a></h5></td>
					</tr>
					<tr>
						<td  style="border: none;background-color: #fcf3ec;"><h5><nobr>10:20AM-10:40AM</nobr></h5></td>
						<td  style="border: none;background-color: #fcf3ec;"><h5><a href="#talk2">Talk 2: BOOM-Explorer: RISC-V BOOM Microarchitecture Design Space Exploration Framework</a></h5></td>
					</tr>
					<tr>
						<td  style="border: none;background-color: #fcf3ec;"><h5><nobr>10:40AM-11:00AM</nobr></h5></td>
						<td  style="border: none;background-color: #fcf3ec;"><h5><a href="#talk3">Talk 3: APOLLO: An Automated Power Modeling Framework for Runtime Power Introspection in High-Volume Commercial Microprocessors</a></h5></td>
					</tr>
					<tr>
						<td  style="border: none;background-color: #fcf3ec;"><h5><nobr>11:00AM-11:20AM</nobr></h5></td>
						<td  style="border: none;background-color: #fcf3ec;"><h5><a href="#talk4">Talk 4: Gemmini: Enabling Systematic Deep-Learning Architecture Evaluation via Full-Stack Integration</a></h5></td>
					</tr>
				</h5></table>
				<h2>April 12, 2022 (EDT/UTC-4)</h2>
				<table style="border: none;"><h5>
					<tr>
						<td  style="border: none;background-color: #fcf3ec;"><h5><nobr>10:00AM-10:20AM</nobr></h5></td>
						<td  style="border: none;background-color: #fcf3ec;"><h5><a href="#talk5">Talk 5: DREAMPlace: Deep Learning Toolkit-Enabled GPU Acceleration for Modern VLSI Placement</a></h5></td>
					</tr>
					<tr>
						<td  style="border: none;background-color: #fcf3ec;"><h5><nobr>10:20AM-10:40AM</nobr></h5></td>
						<td  style="border: none;background-color: #fcf3ec;"><h5><a href="#talk6">Talk 6: TreeNet: Deep Point Cloud Embedding for Routing Tree Construction</a></h5></td>
					</tr>
					<tr>
						<td  style="border: none;background-color: #fcf3ec;"><h5><nobr>10:40AM-11:00AM</nobr></h5></td>
						<td  style="border: none;background-color: #fcf3ec;"><h5><a href="#talk7">Talk 7: Intermittent-Aware Neural Architecture Search</a></h5></td>
					</tr>
					<tr>
						<td  style="border: none;background-color: #fcf3ec;"><h5><nobr>11:00AM-11:20AM</nobr></h5></td>
						<td  style="border: none;background-color: #fcf3ec;"><h5><a href="#talk8">Talk 8: A GPU-accelerated Deep Stereo-LiDAR Fusion for Real-time High-precision Dense Depth Sensing</a></h5></td>
					</tr>
				</h5></table>			
			</div>
		</div>
		<br>
		<!-- Talks detail -->
		<div class="wrapper row3" id="talk1">
			<div class="">
				<h2>Talk 1: Hardware/Software Co-Exploration of Neural Architectures<br>(10AM-10:20AM, EDT/UTC-4, April 11, 2022)</h2>
				<p style="text-align: justify;">We propose a novel hardware and software co-exploration framework for efficient neural architecture search (NAS). Different from existing hardware-aware NAS which assumes a fixed hardware design and explores the NAS space only, our framework simultaneously explores both the architecture search space and the hardware design space to identify the best neural architecture and hardware pairs that maximize both test accuracy and hardware efficiency. Such a practice greatly opens up the design freedom and pushes forward the Pareto frontier between hardware efficiency and test accuracy for better design tradeoffs. The framework iteratively performs a twolevel (fast and slow) exploration. Without lengthy training, the fast exploration can effectively fine-tune hyperparameters and prune inferior architectures in terms of hardware specifications, which significantly accelerates the NAS process. Then, the slow exploration trains candidates on a validation set and updates a controller using the reinforcement learning to maximize the expected accuracy together with the hardware efficiency. In this article, we demonstrate that the co-exploration framework can effectively expand the search space to incorporate models with high accuracy, and we theoretically show that the proposed two-level optimization can efficiently prune inferior solutions to better explore the search space. The experimental results on ImageNet show that the co-exploration NAS can find solutions with the same accuracy, 35.24% higher throughput, 54.05% higher energy efficiency, compared with the hardware-aware NAS.</p>
				
			</div>
			<hr>
			<div>
				<img class="imgr borderedbox inspace-5" src="images/WeiwenJiang.jpg" alt="">
				<h3>Weiwen Jiang</h3>
				<h4>University of Notre Dame</h4>
				<h4>wjiang8@gmu.edu</h4>
				<p style="text-align: justify;">Dr. Weiwen Jiang joined the ECE department at George Mason University as an Assistant Professor in Fall 2021. He was a Postdoctoral Associate at the University of Notre Dame. He received the Ph.D. degree from Chongqing University in 2019. From 2017 to 2019, he was a research scholar at the University of Pittsburgh. His research works have won Best Paper Awards in IEEE TCAD'21, ICCD'17, and NVMSA'15. He is the receipt of four Best Paper Nominations in ASP-DAC'16, DAC'19, CODES+ISSS'19, ASP-DAC'20, and the Top Winning Awards at IEEE Services Hackathon. He built the first co-design framework, QuantumFlow, to demonstrate the quantum advantage in designing neural network onto a quantum computer, which was published in Nature Communications.</p>
			</div>
		</div>
		
		<!-- ################################################################################################ -->
		<div class="wrapper row4" id="talk2">
			<div>
				<h2 >Talk 2: BOOM-Explorer: RISC-V BOOM Microarchitecture Design Space Exploration Framework<br>(10:20AM-10:40AM, EDT/UTC-4, April 11, 2022)</h2>
				<p style="text-align: justify;">The microarchitecture design of a processor has been increasingly difficult due to the large design space and time-consuming verification flow. Previously, researchers rely on prior knowledge and cycle-accurate simulators to analyze the performance of different microarchitecture designs but lack sufficient discussions on methodologies to strike a good balance between power and performance. This work proposes an automatic framework to explore microarchitecture designs of the RISCV Berkeley Out-of-Order Machine (BOOM), termed as BOOM-Explorer, achieving a good trade-off on power and performance. Firstly, the framework utilizes an advanced microarchitecture-aware active learning (MicroAL) algorithm to generate a diverse and representative initial design set. Secondly, a Gaussian process model with deep kernel learning functions (DKL-GP) is built to characterize the design space. Thirdly, correlated multi-objective Bayesian optimization is leveraged to explore Pareto-optimal designs. Experimental results show that BOOM-Explorer can search for designs that dominate previous arts and designs developed by senior engineers in terms of power and performance within a much shorter time.</p>
			</div>
			<hr>
			<div>
				<img class="imgr borderedbox inspace-5" src="images/BeiYu.jpg" alt="">
				<h3>Bei Yu</h3>
				<h4>The Chinese University of Hong Kong</h4>
				<h4>byu@cse.cuhk.edu.hk</h4>
				<p style="text-align: justify;">Bei Yu is an Associate Professor at the Department of Computer Science and Engineering, The Chinese University of Hong Kong. He received the Ph.D degree from Electrical and Computer Engineering, University of Texas at Austin, USA in 2014, and the M.S. degree in Computer Science from Tsinghua University, China in 2010. His current research interests include machine learning and combinatorial algorithm with applications in electronic design automation (EDA) and computer vision. He has served as TPC Chair of 1st ACM/IEEE Workshop on Machine Learning for CAD (MLCAD), served in the program committees of DAC, ICCAD, DATE, ASPDAC, ISPD, the editorial boards of ACM Transactions on Design Automation of Electronic Systems (TODAES), Integration, the VLSI Journal, and IET Cyber-Physical Systems: Theory & Applications. He is Editor of IEEE TCCPS Newsletter and Chair of IEEE CEDA Hong Kong Chapter.<br>
				Dr. Yu received nine Best Paper Awards from Design, Automation and Test in Europe Conference (DATE) 2022, International Conference on Computer-Aided Design (ICCAD) 2021 & 2013, Asia and South Pacific Design Automation Conference (ASPDAC) 2021 & 2012, International Conference on Tools with Artificial Intelligence (ICTAI) 2019, Integration, the VLSI Journal in 2018, International Symposium on Physical Design (ISPD) 2017, SPIE Advanced Lithography Conference 2016, five other Best Paper Award Nominations (DATE 2021, ASPDAC 2019, DAC 2014, ASPDAC 2013, and ICCAD 2011), seven ICCAD/ISPD/ICDAR contest awards, IBM Ph.D. Scholarship in 2012, SPIE Education Scholarship in 2013, and EDAA Outstanding Dissertation Award in 2014.</p>
				<br>
				<img class="imgr borderedbox inspace-5" src="images/baichen.jpg" alt="">
				<h3>Bai Chen</h3>
				<h4>The Chinese University of Hong Kong</h4>
				<h4>cbai@cse.cuhk.edu.hk</h4>
				<p style="text-align: justify;">I am currently a second-year Ph.D. student at the Department of Computer Science and Engineering of The Chinese University of Hong Kong under the supervision of Prof. Bei Yu and co-supervised by Prof. Martin D.F. Wong. Previously, I received my B.Eng. from The University of Electronic Science and Technology of China (UESTC) in 2020.</p>
			</div>
		</div>		

		<!-- ################################################################################################ -->

		<div class="wrapper row3" id="talk3">
			<div>
				<h2 >Talk 3: APOLLO: An Automated Power Modeling Framework for Runtime Power Introspection in High-Volume Commercial Microprocessors<br>(10:40AM-11AM, EDT/UTC-4, April 11, 2022)</h2>
				<p style="text-align: justify;">Accurate power modeling is crucial for energy-efficient CPU design and runtime management. An ideal power modeling framework needs to be accurate yet fast, achieve high temporal resolution (ideally cycle-accurate) yet with low runtime computational overheads, and easily extensible to diverse designs through automation. Simultaneously satisfying such conflicting objectives is challenging and largely unattained despite significant prior research. In this talk, I will introduce our work APOLLO with multiple key attributes. First, it supports fast and accurate design-time power model simulation, handling millions-of-cycles benchmarks in minutes with an emulator. Second, it incorporates an unprecedented low-cost runtime on-chip power meter in CPU RTL for per-cycle power tracing. Third, the development process of this method is fully automated and applies to any given design solution. This method has been validated on high-volume commercial microprocessors Neoverse N1 and Cortex-A77. </p>
			</div>
			<hr>
			<div>
				<img class="imgr borderedbox inspace-5" src="images/ZhiyaoXie.jpg" alt="">
				<h3>Zhiyao Xie</h3>
				<h4>The Hong Kong University of Science and Technology</h4>
				<h4>eezhiyao@ust.hk</h4>
				<p style="text-align: justify;">I am an Assistant Professor at the ECE Department of Hong Kong University of Science and Technology (HKUST). I received my Ph.D. degree from ECE Department of Duke University in 2022, advised by Prof. Yiran Chen and Prof. Hai (Helen) Li and B.Eng. degree from City University of Hong Kong in 2017. My research interests include cross-disciplinary topics in electronic design automation, VLSI design, computer architecture, and machine learning. I am especially experienced in machine learning for hardware design. I am the recipient of MICRO 2021 Best Paper Award.</p>
				
			</div>
		</div>

		<!-- ################################################################################################ -->
		<div class="wrapper row4" id="talk4">
			<div>
				<h2 >Talk 4: Gemmini: Enabling Systematic Deep-Learning Architecture Evaluation via Full-Stack Integration<br>(11AM-11:20AM, EDT/UTC-4, April 11, 2022)</h2>
				<p style="text-align: justify;">DNN accelerators are often developed and evaluated in isolation without considering the cross-stack, system-level effects in real-world environments. This makes it difficult to appreciate the impact of Systemon-Chip (SoC) resource contention, OS overheads, and programming-stack inefficiencies on overall performance/energy-efficiency. To address this challenge, we present Gemmini, an open-source, full-stack DNN accelerator generator. Gemmini generates a wide design-space of efficient ASIC accelerators from a flexible architectural template, together with flexible programming stacks and full SoCs with shared resources that capture system-level effects. Gemmini-generated accelerators have also been fabricated, delivering up to three orders-of-magnitude speedups over high-performance CPUs on various DNN benchmarks.</p>
			</div>
			<hr>
			<div>
				<img class="imgr borderedbox inspace-5" src="images/shao.jpg" alt="">
				<h3>Sophia Shao</h3>
				<h4>University of California, Berkeley</h4>
				<h4>ysshao@berkeley.edu</h4>
				<p style="text-align: justify;">I am an Assistant Professor and an SK Hynix Faculty Fellow at the Electrical Engineering and Computer Sciences department of University of California, Berkeley. Previously, I was a Senior Research Scientist at NVIDIA Research. I received my Ph.D. degree in 2016 and S.M. degree in 2014 from Harvard University. My research interests are in the area of computer architecture, with a special focus on specialized accelerator, heterogeneous architecture, and agile VLSI design methodology. My work has been awarded the Best Paper Award at DAC 2021, the Best Paper Award at JSSC 2020, a Best Paper Award at MICRO 2019, Top Picks in Computer Architecture (2014), and Honorable Mentions (2019*2). My Ph.D. dissertation was nominated by Harvard for ACM Doctoral Dissertation Award. I am an SK Hynix Faculty Fellow and a recipient of a Google Faculty Rising Stars Award in Systems Research, a Facebook Research Award, and the inaugural Dr. Sudhakar Yalamanchili Award.</p>
			</div>
		</div>
		
		<!-- ################################################################################################ -->
		<div class="wrapper row3" id="talk5">
			<div>
				<h2 >Talk 5: DREAMPlace: Deep Learning Toolkit-Enabled GPU Acceleration for Modern VLSI Placement<br>(10AM-10:20AM, EDT/UTC-4, April 12, 2022)</h2>
				<p style="text-align: justify;">Placement for very large-scale integrated (VLSI) circuits is one of the most important steps for design closure. We propose a novel GPU-accelerated placement framework DREAMPlace, by casting the analytical placement problem equivalently to training a neural network. Implemented on top of a widely adopted deep learning toolkit PyTorch, with customized key kernels for wirelength and density computations, DREAMPlace can achieve around 40Ã— speedup in global placement without quality degradation compared to the state-of-the-art multithreaded placer RePlAce. We believe this work shall open up new directions for revisiting classical EDA problems with advancements in AI hardware and software.</p>
				
			</div>
			<hr>
			<div>
				<img class="imgr borderedbox inspace-5" src="images/YiboLin.jpg" alt="">
				<h3>Yibo Lin</h3>
				<h4>Peking University</h4>
				<h4>yibolin@pku.edu.cn</h4>
				<p style="text-align: justify;">I am an assistant professor in the School of Integrated Circuits at Peking University. I received the Ph.D. degree in Electrical and Computer Engineering from the University of Texas at Austin in 2018 advised by Prof. David Z. Pan and the B.S. degree in Microelectronics from Shanghai Jiaotong University in 2013. My research interests include physical design, machine learning applications, emerging technology in VLSI CAD, and hardware acceleration. I am a recipient of the Best Paper Awards at DATE 2022, TCAD 2021, DAC 2019, Integration, the VLSI Journal 2018, and SPIE Advanced Lithography Conference 2016.</p>
				
			</div>
		</div>



		<!-- ################################################################################################ -->

		<div class="wrapper row4" id="talk6">
			<div>
				<h2 >Talk 6: TreeNet: Deep Point Cloud Embedding for Routing Tree Construction<br>(10:20AM-10:40AM, EDT/UTC-4, April 12, 2022)</h2>
				<p style="text-align: justify;">In the routing tree construction, both wirelength (WL) and pathlength (PL) are of importance. Among all methods, PD-II and SALT are the two most prominent ones. However, neither PD-II nor SALT always dominates the other one in terms of both WL and PL for all nets. In addition, estimating the best parameters for both algorithms is still an open problem. In this paper, we model the pins of a net as point cloud and formalize a set of special properties of such point cloud. Considering these properties, we propose a novel deep neural net architecture, TreeNet, to obtain the embedding of the point cloud. Based on the obtained cloud embedding, an adaptive workflow is designed for the routing tree construction. Experimental results show that the proposed TreeNet is superior to other mainstream models for the point cloud on classification tasks. Moreover, the proposed adaptive workflow for the routing tree construction outperforms SALT and PD-II in terms of both efficiency and effectiveness.</p>
			</div>
			<hr>
			<div>
				<img class="imgr borderedbox inspace-5" src="images/yuzhe.jpg" alt="">
				<h3>Yuzhe Ma</h3>
				<h4>Hong Kong University of Science and Technology</h4>
				<h4>yuzhema@ust.hk</h4>
				<p style="text-align: justify;">I am an Assistant Professor at the Microelectronics Thrust of The Hong Kong University of Science and Technology (Guangzhou) . Previously, I was a Senior Research Scientist at Huawei Hong Kong Research Center. I received my Ph.D. degree in 2020 from The Chinese University of Hong Kong advised by Prof. Bei Yu. My research interests are on the cross-disciplinary study of electronic design automation and machine learning, including agile VLSI design methodologies, machine learning-aided VLSI design, and hardware-friendly machine learning. I am a recipient of the Best Paper Awards at ICCAD 2021, ASPDAC 2021, and ICTAI 2019.</p>
				
			</div>
		</div>
		<!-- ################################################################################################ -->

		<div class="wrapper row3" id="talk7">
			<div>
				<h2 >Talk 7: Intermittent-Aware Neural Architecture Search<br>(10:40AM-11AM, EDT/UTC-4, April 12, 2022)</h2>
				<p style="text-align: justify;">Intermittently executing deep neural network (DNN) inference powered by ambient energy, paves the
way for sustainable and intelligent edge applications. Neural architecture search (NAS) has achieved great
success in automatically finding highly accurate networks with low latency. However, we observe that
NAS attempts to improve inference latency by primarily maximizing data reuse, but the derived solutions
when deployed on intermittent systems may be inefficient, such that the inference may not satisfy an
end-to-end latency requirement and, more seriously, they may be unsafe given an insufficient energy
budget. This work proposes iNAS, which introduces intermittent execution behavior into NAS. In order to
generate accurate neural networks and corresponding intermittent execution designs that are safe and
efficient, iNAS finds the right balance between data reuse and the costs related to progress preservation
and recovery, while ensuring the power-cycle energy budget is not exceeded. The solutions found by iNAS
and an existing HW-NAS were evaluated on a Texas Instruments device under intermittent power, across
different datasets, energy budgets and latency requirements. Experimental results show that in all cases
the iNAS solutions safely meet the latency requirements, and substantially improve the end-to-end
inference latency compared to the HW-NAS solutions.</p>
			</div>
			<hr>
			<div>
				<img class="imgr borderedbox inspace-5" src="images/pchsiu.jpg" alt="">
				<h3>Pi-Cheng Hsiu</h3>
				<h4>Academic Sinica</h4>
				<h4>pchsiu@citi.sinica.edu.tw</h4>
				<p style="text-align: justify;">Pi-Cheng Hsiu is a Research Fellow and Deputy Director of the Research Center for Information
Technology Innovation (CITI), Academia Sinica, where he leads the Embedded and Mobile Computing
Laboratory, and is a Jointly Appointed Professor with National Taiwan University and with National Chi
Nan University. Upon receipt of the Ph.D. degree in computer science and information engineering from
National Taiwan University, he joined CITI as an Assistant Research Fellow in 2009, and was promoted to
an Associate Research Fellow in 2013 and to a Research Fellow in 2018. He was a Visiting Scholar with the
University of Illinois at Urbana-Champaign in 2007 and with the University of Pittsburgh in 2019.<br>
Dr. Hsiu's research goal is to realize Intermittent Artificial of Things (iAIoT), enabling battery-less IoT
devices to intermittently execute deep neural networks via ambient power. His work has been awarded
the Best Paper Award at IEEE/ACM CODES+ISSS 2020 and 2021 in a row, and nominated for the Best Paper
Award in 2019. He is a recipient of the 2021-22 Outstanding Elite Award of the Chung Hwa Rotary
Educational Foundation, the 2019 Young Scholars Creativity Award of the Foundation for the
Advancement of Outstanding Scholarship, the 2019 Exploration Research Award of the Pan Wen Yuan
Foundation, and the 2015 Scientific Paper Award of the Y. Z. Hsu Science and Technology Memorial
Foundation.</p>
				<br>
				<img class="imgr borderedbox inspace-5" src="images/rosh.jpg" alt="">
				<h3>Hashan Roshantha Mendis</h3>
				<h4>Academic Sinica</h4>
				<h4>rosh.mendis@citi.sinica.edu.tw</h4>
				<p style="text-align: justify;">Hashan Roshantha Mendis is currently a Postdoctoral Research Fellow at the Research Center for
Information Technology Innovation (CITI), Academia Sinica, Taiwan. He received his MSc. and Eng.D
degrees respectively from the Department of Electronics and Department of Computer Science in the
University of York, UK, in 2011 and 2017. His research interests include intermittently-powered embedded
systems, embedded deep learning, as well as the design and optimization of multi/many-core systems.
His work has received the Best Paper Award at CODES+ISSS 2020 and 2021, nominated for the Best Paper
Award at CODES+ISSS 2019 and the Best Student Paper Award at SIGMAP 2016.</p>
			</div>
		</div>

		<!-- ################################################################################################ -->
		<div class="wrapper row4" id="talk8">
			<div>
				<h2 >Talk 8: A GPU-accelerated Deep Stereo-LiDAR Fusion for Real-time High-precision Dense Depth Sensing<br>(11AM-1:20AM, EDT/UTC-4, April 12, 2022)</h2>
				<p style="text-align: justify;">Active LiDAR and stereo vision are the most commonly used depth sensing techniques in autonomous vehicles. Each of them alone has weaknesses in terms of density and reliability and thus cannot perform well on all practical scenarios. Recent works use deep neural networks (DNNs) to exploit their complementary properties, achieving a superior depth-sensing. However, these state-of-the-art solutions are not satisfactory on real-time responsiveness due to the high computational complexities of DNNs. In this paper, we present FastFusion, a fast deep stereo-LiDAR fusion framework for real-time high-precision depth estimation. FastFusion provides an efficient two-stage fusion strategy that leverages binary neural network to integrate stereoLiDAR information as input and use cross-based LiDAR trust aggregation to further fuse the sparse LiDAR measurements in the back-end of stereo matching. More importantly, we present a GPU-based acceleration framework for providing a low latency implementation of FastFusion, gaining both accuracy improvement and real-time responsiveness. In the experiments, we demonstrate the effectiveness and practicability of FastFusion, which obtains a significant speedup over state-of-the-art baselines while achieving comparable accuracy on depth sensing.</p>
			</div>
			<hr>
			<div>
				<img class="imgr borderedbox inspace-5" src="images/chen.jpg" alt="">
				<h3>Gang Chen</h3>
				<h4>Sun Yat-sen University</h4>
				<h4>cheng83@mail.sysu.edu.cn</h4>
				<p style="text-align: justify;">Gang Chen is currently an Associate Professor at the school of Computer Science, Sun Yat-sen University. He received his PhD degree in Computer Science in 2016, from Technical University of Munich, Germany, and his M.S. degree in Control Science and Engineering in 2011, from Xi'an Jiaotong University, China. He is a recipient of the best paper awards on DATE 2021, ICET 2021, and ESTImedia 2020 and best paper candidate awards on CODES+ISSS 2020. He serves as an Associate Editor of the Journal of Circuits, Systems and Computers. His research interests include high-performance computing and embedded systems design particularly for the automotive and robotics domain.</p>
				<br>
				<img class="imgr borderedbox inspace-5" src="images/meng.jpg" alt="">
				<h3>Haitao Meng</h3>
				<h4>Technical University of Munich</h4>
				<h4>Haitao.meng@tum.de</h4>
				<p style="text-align: justify;">Haitao Meng currently is studying for his PhD degree at Technical University of Munich under the supervision of Prof. Alois Knoll and co-supervised by Prof. Gang Chen. He received M.Sc degree in computer science from Northeastern University, China. He is a recipient of the best paper award on DATE 2021 and best paper candidate award on CODES+ISSS 2020. His research interests include stereo estimation, high-performance computing, and real-time images processing.</p>
			</div>
		</div>

	</div>
  </main>
</div>
<!-- ################################################################################################ -->
<!-- Footer information -->
<div class="wrapper row0">
  <footer id="footer" class="hoc clear"> 
    <!-- ################################################################################################ -->
	<div class="one_third first">
		<h6 class="heading">Contact</h6>
		<p>Tel: 886-2-2788-3799 #1612<br>
		Fax:886-2-2782-4814<br>
		<a href="mailto:johnson@iis.sinica.edu.tw">johnson@iis.sinica.edu.tw</a><br><br>
		128 Academia Road, Section 2, Nankang, Taipei 11529, Taiwan</p>
<!--  Social media -->
<!--  <ul class="faico clear">
        <li><a class="faicon-dribble" href="#"><i class="fab fa-dribbble"></i></a></li>
        <li><a class="faicon-facebook" href="#"><i class="fab fa-facebook"></i></a></li>
        <li><a class="faicon-google-plus" href="#"><i class="fab fa-google-plus-g"></i></a></li>
        <li><a class="faicon-linkedin" href="#"><i class="fab fa-linkedin"></i></a></li>
        <li><a class="faicon-twitter" href="#"><i class="fab fa-twitter"></i></a></li>
        <li><a class="faicon-vk" href="#"><i class="fab fa-vk"></i></a></li>
    </ul>-->
    </div>
	<!-- Orgnized by -->
	<div class="one_third">
      <h6 class="heading">Orgnized by</h6>
      <p><t>ACM SIGDA </t><img src="images/sigda.png" alt="" ></p>
      <p><t>IEEE CEDA  </t><img src="images/ceda.png" alt=""></p>
    </div>
	<!-- Sponsor -->
	<div class="one_third">
	  <h6 class="heading">Sponsor</h6>
	  <p><t>Synopsys </t><img src="images/synopsys.png" alt=""></p>
	  <p><t>HUAWEI </t><img src="images/huawei.jpg" alt=""></p>
    </div>
    <!-- ################################################################################################ -->
  </footer>
</div>
<!-- Sponsor -->
<a id="backtotop" href="#top"><i class="fas fa-chevron-up"></i></a>
<!-- JAVASCRIPTS -->
<script src="layout/scripts/jquery.min.js"></script>
<script src="layout/scripts/jquery.backtotop.js"></script>
<script src="layout/scripts/jquery.mobilemenu.js"></script>
<script type="text/javascript" src="js/sticky-sidebar.js"></script>
</body>
</html>